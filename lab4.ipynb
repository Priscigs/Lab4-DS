{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 4: Mejorando el Análisis de Sentimientos con LSTM y Características Adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los datos...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 12s 1us/step\n"
     ]
    }
   ],
   "source": [
    "print('Cargando los datos...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir padding a las palabras o recortarlas en caso fuera el caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen = 100)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Embedding(50000, 128))\n",
    "modelo.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "modelo.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 150s 191ms/step - loss: 0.4272 - accuracy: 0.7962 - val_loss: 0.3490 - val_accuracy: 0.8525\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 154s 198ms/step - loss: 0.2227 - accuracy: 0.9135 - val_loss: 0.3558 - val_accuracy: 0.8415\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 153s 196ms/step - loss: 0.1272 - accuracy: 0.9538 - val_loss: 0.4640 - val_accuracy: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29b02f6a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrena el modelo\n",
    "modelo.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 20s 25ms/step - loss: 0.4640 - accuracy: 0.8352\n"
     ]
    }
   ],
   "source": [
    "# Evalúa el desempeño del modelo\n",
    "score, accuracy = modelo.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación de la pérdida: 0.4640200734138489\n",
      "Precisión: 0.8352000117301941\n"
     ]
    }
   ],
   "source": [
    "print(f'Puntuación de la pérdida: {score}')\n",
    "print(f'Precisión: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este informe, se presenta un modelo de análisis de sentimientos desarrollado para clasificar reseñas de películas en positivas o negativas. Se utilizó un conjunto de datos de reseñas de películas del conjunto IMDb. El objetivo del laboratorioo fue desarrollar un modelo de clasificación binaria con un enfoque en mejorar el rendimiento en comparación con un modelo básico.\n",
    "\n",
    "### 1. Características Adicionales Seleccionadas\n",
    "\n",
    "Para mejorar el rendimiento del modelo, se implementaron las siguientes características adicionales:\n",
    "\n",
    "- Capa de Dropout: Se añadió una capa de Dropout con una tasa del 30% después de la capa LSTM. Esta capa ayuda a prevenir el sobreajuste al apagar aleatoriamente neuronas durante el entrenamiento, lo que fomenta una representación más general del modelo.\n",
    "- Tamaño de Embedding: Se mantuvo el tamaño del espacio de embedding en 128. Esto proporciona una representación densa de las palabras, lo que facilita al modelo aprender patrones semánticos más complejos.\n",
    "\n",
    "### 2. Arquitectura del Modelo y Justificación\n",
    "\n",
    "El modelo consta de tres capas principales:\n",
    "\n",
    "- Capa de Embedding: Con 50,000 palabras en el vocabulario, se eligió un espacio de embedding de 128 para representar las palabras. Esto permite una representación densa y significativa de las palabras en el espacio vectorial.\n",
    "- Capa LSTM: Se utilizó una capa LSTM con 128 unidades para capturar relaciones temporales y contextuales en las secuencias de texto. Esto es crucial para comprender el contexto y la dependencia a lo largo de las reseñas.\n",
    "- Capa de Salida (Densa): Una capa densa con una unidad y activación sigmoide fue seleccionada para realizar la clasificación binaria. La activación sigmoide produce una probabilidad entre 0 y 1, lo que es adecuado para un problema de clasificación binaria.\n",
    "\n",
    "### 3. Resultados Obtenidos y Comparación\n",
    "\n",
    "Con el modelo entrenado se obtuvo los siguientes resultados:\n",
    "\n",
    "- Pérdida: 0.4640\n",
    "- Precisión: 83.52%\n",
    "-- Este modelo mejorado logró una mejora significativa en la precisión, ya que una pérdida de 0.46 indica que el modelo está bastante bien ajustado a los datos. Cuanto más cercana a cero sea la pérdida, mejor es el rendimiento. Por otra parte, el acuraccy de 83.52% es bastante bueno, especialmente hablando para un modelo de lenguaje natural, pero no siempre significa que este no vaya a cometer errores. Esto indica que la inclusión de características adicionales, como la capa de Dropout y una capa LSTM, ha tenido un impacto positivo en el rendimiento del modelo.\n",
    "\n",
    "## Conclusiones y Recomendaciones\n",
    "\n",
    "El modelo mejorado demostró una notable mejora en la precisión en comparación con el modelo básico. Esto sugiere que la incorporación de capas adicionales y el ajuste de hiperparámetros pueden conducir a un mejor rendimiento. Se recomienda seguir experimentando con diferentes configuraciones de capas y parámetros para continuar optimizando el modelo. También es importante considerar la posibilidad de aumentar el tamaño del conjunto de datos o explorar técnicas de procesamiento de texto más avanzadas para futuras iteraciones del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
